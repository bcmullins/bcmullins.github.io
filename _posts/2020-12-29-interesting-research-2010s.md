---
layout: post
title: Interesting Research Programs from the 2010s
categories: Review
mathjax: true
---

The idea of this post is to introduce and discuss several interesting research programs from the past decade. A [research program](https://en.wikipedia.org/wiki/Research_program) (or programme) refers to a common thread of research that shares similar assumptions, methodology, etc. The list below contains a variety of research programs: some on topics that have broad appeal e.g. [explainable machine learning](#machine-learning-interpretability-and-explainability) and [mental disorder](#the-disordered-mind-theory-of-mental-illness); others moved the direction of entire industries e.g. advances in [computer vision](#image-recognition-and-object-detection) and [cryptocurrencies](#blockchains-and-cryptocurrencies); and others still are more niche areas that I happen to be deeply interested in e.g. [topological learning theory](#topological-learning-theory), [privacy attacks on ML models](#privacy-attacks-on-machine-learning-models), and [graph-theoretic approaches to epistemology](#the-graph-theoretic-approach-to-epistemic-justification).

Obviously, a list of this variety can never be complete and is surely biased by what I happen to be reading. If I've missed something interesting that you enjoy, let me know at brettcmullins(at)gmail.com. Enjoy!

## Image Recognition and Object Detection
______

It is difficult for me to begin this list without first talking about the area that most affected my professional career, led to (or at least accelerated) a boom in data science, and [potentially thawed an AI winter](https://www.skynettoday.com/overviews/neural-net-history). During the 2010s, [deep learning made enormous progress](https://bmk.sh/2019/12/31/The-Decade-of-Deep-Learning/) in heuristics and applications. For [computer vision](https://en.wikipedia.org/wiki/Computer_vision) in particular, a good starting point is [AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) in 2012 which used a [convolutional neural network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network) architecture to substantially surpass existing benchmarks for image recognition - the task of assigning a label such as _cat_, _dog_, or _tree_ to an image - on the [ImageNet dataset](http://image-net.org/). Over the next few years, improvements would continue with architectures such as [VGG](https://towardsdatascience.com/vgg-neural-networks-the-next-step-after-alexnet-3f91fa9ffe2c), [ResNet](https://en.wikipedia.org/wiki/Residual_neural_network), and [Inception](https://arxiv.org/pdf/1409.4842.pdf).


<figure style="float: right; display: table; margin: 0px 0px 0px 25px">
  <img style="float: right;" src="/images/blog/researchPrograms2010s/recognition.png" width="300" height="250" >
  <figcaption style="text-align: center; display: table-caption; caption-side: bottom;"> Example output from R-CNN. Source: <a href="https://arxiv.org/abs/1311.2524">the R-CNN paper.</a></figcaption>
</figure>

With progress being made with recognition, other tasks such as object detection - finding and labeling objects (sometimes multiple objects) within images - became more feasible. One approach to object detection introduced in 2013 [Regional CNNs (or R-CNNs)](https://arxiv.org/abs/1311.2524) combined a model that first produced promising bounding boxes then utilized the newly developed recognition models (starting with AlexNet) to classify or label the regions in the bounding boxes. Over the next few years, progress in this direction was realized with [Fast R-CNN](https://arxiv.org/abs/1504.08083) and [Faster R-CNN](https://arxiv.org/abs/1504.08083). These frameworks not only employed better recognition models and found better bounding boxes, but they integrated the model components together so that they could be more efficiently trained or tailored to one's application. [Here is an excellent overview](https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4) of these models with a bit more detail.

Accompanying these new techniques and improvements was a large amount of software - with [TensorFlow](https://en.wikipedia.org/wiki/TensorFlow), [Caffe](https://en.wikipedia.org/wiki/Caffe_(software)), and [Torch](https://en.wikipedia.org/wiki/Torch_(machine_learning)) at first then the more user friendly [Keras](https://en.wikipedia.org/wiki/Keras) - allowing anyone to implement these models for their use cases. It's also worth mentioning the proliferation of online courses such as [fast.ai's](https://fast.ai) [Practical Deep Learning for Coders](https://course.fast.ai/) that facilitated getting potential users up to speed to test out and deploy these tools.

## Topological Learning Theory
______

Topological Learning Theory is the mathematical study of the learnability/solvability of hypotheses/problems that is informed by the [theory of computation](https://en.wikipedia.org/wiki/Computability_theory) and [descriptive set theory](https://en.wikipedia.org/wiki/Descriptive_set_theory) rather than [classical statistics](https://en.wikipedia.org/wiki/Frequentist_inference) (with [statistical learning theory](https://en.wikipedia.org/wiki/Statistical_learning_theory)). The idea of learning theory is to analyze the learnability of hypotheses as one incrementally receives information about the true state of the world.


<img style="float: right; display: inline-block; margin: 10px 0px 10px 25px" src="/images/blog/researchPrograms2010s/ravens.jpeg" width="200" height="350" >

A [classic example](https://plato.stanford.edu/entries/learning-formal/#1.1) is to consider an ornithologist observing the color of ravens as, say, black or not. With each raven observed, the ornithologist gains information which rules out some hypotheses but is consistent with others. By coding a black raven as 1 and other ravens as 0, we can mathematically represent possible observation histories as infinite sequences of 0s and 1s, i.e. points in the [Cantor space](https://en.wikipedia.org/wiki/Cantor_space). The crux of this approach is that the [topology on the Cantor space and other such spaces](http://www.personal.psu.edu/jsr25/Spring_11/Lecture_Notes/dst_lecture_notes_2011_lec_2.pdf) naturally [encodes the idea of information accumulation](http://www.andrew.cmu.edu/user/kk3n/kelly/learnreview.pdf). By considering the [descriptive complexity of hypotheses](https://en.wikipedia.org/wiki/Borel_hierarchy), identifying a hypothesis with the set of sequences that make it true, we can say things about the learnability of the hypothesis. For instance, the hypothesis "all ravens are black" is the set containing the single sequence of all 1s. We say that this hypothesis is falsifiable since if there is a non-black raven our ornithologist will eventually observe it; however, it is verifiable not in finite time but in the limit since the hypothesis is never conclusively true after any finite number of observations. This corresponds to the topological notion of properly being an [$F_{\sigma}$ or $\Sigma^{0}_{2}$ set](https://en.wikipedia.org/wiki/F%CF%83_set).

[Kevin Kelly's](https://www.cmu.edu/dietrich/philosophy/people/faculty/kevin-kelly.html) 1996 [_The Logic of Reliable Inquiry_](https://global.oup.com/academic/product/the-logic-of-reliable-inquiry-9780195091953?cc=us&lang=en&) has been an authoritative text on formal learning theory in the Cantor space and other [Polish spaces](https://ncatlab.org/nlab/show/Polish+space). Advances in [computable analysis](https://ncatlab.org/nlab/show/computable+analysis) beginning in the early 2000s have enabled the extension of these classical formal learning theory results to a more general topological setting throughout the 2010s. The paper [_Topological Properties of Concept Spaces_](https://www.sciencedirect.com/science/article/pii/S0890540109001631?via%3Dihub) from 2010 is the first to connect these computable analysis results to learning theory. By 2015, a pair of papers [_On the Solvability of Inductive Problems_](https://arxiv.org/abs/1606.07518) and [_Theory Choice, Theory Change, and Inductive Truth-Conduciveness_](https://www.imsc.res.in/tark/TARK2015-proceedings.pdf#page=119) - both presented at the [TARK 2015 conference](https://www.imsc.res.in/tark/tark15.html) - provide complete topological characterizations of learnability/solvability in the limit as well as connections to [belief revision theory](https://plato.stanford.edu/entries/logic-belief-revision/) and [Ockham's Razor](https://en.wikipedia.org/wiki/Occam%27s_razor) in this more general topological setting.

## The Disordered Mind Theory of Mental Illness
______

In a series of articles and books over the past decade, the philosopher [George Graham](https://mitpress.mit.edu/contributors/george-graham) develops a theory of mental disorder with the following qualities: 1. is non-reductionist with respect to the mind and the brain; 2. is informed by the [philosophy of mind](https://en.wikipedia.org/wiki/Philosophy_of_mind); and 3. coheres with the experiences of patients and clinicians. Graham's theory holds that mental illness is distinct from somatic/bodily illness though may co-occur or otherwise be bound up with so-called [broken brains](https://psycnet.apa.org/record/2008-07609-001). A helpful analogy for what is meant here by "the mental" or "the mind" is to view the brain as computer hardware, whereas the mind is software. On this picture, the mind and the brain are surely not independent; a hardware issue may impede the computation of some software. However, one may have bugs in one's software - "gumming up the works" to use a common phrase of Graham - on perfectly functioning hardware.

<img style="float: right; display: inline-block; margin: 10px 0px 10px 25px" src="/images/blog/researchPrograms2010s/graham.jpeg" width="200" height="280" >

This theory of mental disorder is developed in Graham's text on mental illness in the context of the philosophy of mind: [_The Disordered Mind_](https://www.routledge.com/The-Disordered-Mind/Graham/p/book/9780367322328). A follow-up book, [_The Abraham Dilemma_](https://global.oup.com/academic/product/the-abraham-dilemma-9780198728658?cc=us&lang=en&), refines this theory for the case of delusion, religious delusion in particular (I discuss _The Abraham Dilemma_ in greater detail in my [Top Books in 2020]({{ site.baseurl }}{% link _posts/2020-12-21-top-books-2020.md %}#the-abraham-dilemma-a-divine-delusion)). Graham's latest book [_Hearing Voices and Other Matters of the Mind_](https://global.oup.com/academic/product/hearing-voices-and-other-matters-of-the-mind-9780190091149?cc=us&lang=en&) explores the unique properties and challenges of mental disorders in the presence of religious content. The disordered mind theory [is not without its detractors](https://ndpr.nd.edu/news/the-disordered-mind-an-introduction-to-philosophy-of-mind-and-mental-illness/) who hold that Graham goes too far in arguing that one need not situate and commit to positions in the philosophy of mind to reject the complete reduction of mental illness to neuroscience.

I took George Graham's seminar on Philosophy and Mental Illness in 2014 at [Georgia State University](https://philosophy.gsu.edu/) and had several interesting chats with him about the metaphysics and definability of mental disorders.

## Machine Learning Interpretability and Explainability
______

The boom in data science and widespread use of machine learning models during the past decade was accelerated by innovations in model architectures as well as tools and software to train and deploy these models. In addition to the [progress with neural networks and deep learning](#image-recognition-and-object-detection), algorithms such as [XGBoost](https://en.wikipedia.org/wiki/XGBoost) allowed users to achieve state-of-the-art classification and regression performance without much effort. XGBoost in particular became so prevalent in both industry and ML competitions - as had logistic regression and other GLMs in the past - that it was not unreasonable for some to wonder whether or not [we should just use XGBoost all the time](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d).

For all that these models gained in performance, they lost ground in being able to provide answers to questions from stakeholders, developers, and so forth when things went wrong as to why a model's prediction was so far off or why does the computer vision model [think a banana is a toaster](https://arxiv.org/pdf/1712.09665.pdf). Two approaches were offered as a solution (three if you count "Who cares?! Let's do nothing!"): interpretability and explanations. The former offers constraints on model building such as limiting the number of features used and restricting to linear models so that the model is sufficiently simple to allow the developer/user to reliably predict the model’s behavior with a reasonable amount of effort. The latter is a set of methods for generating reasons for a model's behavior for arbitrarily complex models. [_The Mythos of Model Interpretability_](https://arxiv.org/abs/1606.03490) is an early effort to disentangle these terms and map the landscape for understanding models. Also see [my attempt here]({{ site.baseurl }}{% link _posts/2020-02-19-economic_methodology_interpretable_ml_blackboxes.md %}) as well as Christoph Molnar's ever-evolving text [_Interpretable Machine Learning_](https://christophm.github.io/interpretable-ml-book/).

<img style="float: right; display: inline-block;" width="40%" height="40%" src="/images/blog/best_articles_2018/anchor.png">

The approach that I find the most compelling stems from the [LIME paper](https://arxiv.org/abs/1602.04938). LIME (or local interpretable model-agnostic explanations) is a method of generating an interpretable, i.e. linear, approximation of a model in the neighborhood of a given point in the feature space. This new model is then used to generate explanations by virtue of its interpretability. A second approach for classifiers called [Anchors](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf) - both are developed by the [same research group at UW](https://homes.cs.washington.edu/~guestrin/group.html) that also developed XGBoost - produces a simple region of the feature space (a rectangle) where the model's prediction holds with high probability for a given point. This region or anchor acts as a sort of sufficiency condition for classification. The image to the right illustrates these ideas with the dotted line being a local linear approximation and the rectangle being an anchor for points denoted by $+$ and $-$.

Part of my research studies [anchors and other rule-based approaches to local explanation from a topological perspective](https://arxiv.org/abs/1910.08595).

## The Graph-Theoretic Approach to Epistemic Justification
______

[Formal epistemology](https://plato.stanford.edu/entries/formal-epistemology/) is an area of philosophy that uses mathematical tools to study knowledge and belief. One way to represent beliefs is through [directed graphs](https://en.wikipedia.org/wiki/Directed_graph) where nodes are beliefs and edges are relations of inferential support from one belief to another. For instance, for beliefs $P, Q$ we may say that there is an edge $QP$ between the beliefs for a given agent if the agent believes both $P, Q$ and $Pr(P \mid Q) > \alpha $ for some $ \alpha > 0.5$.

<img style="float: right; display: inline-block; margin: 10px 0px 10px 25px" width="25%" height="25%" src="/images/blog/researchPrograms2010s/fading_foundations.jpeg">

In a 2007 paper called [_Infinitism Regained_](https://academic.oup.com/mind/article-abstract/116/463/597/1005610?redirectedFrom=fulltext), [Jeanne Peijnenburg](https://www.rug.nl/staff/jeanne.peijnenburg/research) took the first steps in this literature by showing that these probabilities are well defined under some conditions for infinite chains of beliefs. This refuted a common conceptual objection against [infinitism](https://iep.utm.edu/inf-epis/) in informal epistemology. Peijnenburg along with [David Atkinson](https://www.dropbox.com/s/igg55oeep0huso4/Home%20page.pdf?dl=0) published a dozen or so papers in the first half of the decade developing a theory for relating the structure of relations between beliefs to when conditional probabilities are well defined. The paper [_Justification by an Infinity of Conditional Probabilities_](https://projecteuclid.org/euclid.ndjfl/euclid.ndjfl/1242067709) is representative of this bunch. This line of research culminated in the 2017 monograph [_Fading Foundations_](https://www.springer.com/gp/book/9783319582948) which joined together their results into a coherent story with a bit more exposition than is found in the papers.

It's worth mentioning a second thread of research in this area comes from [Selim Berker's](https://scholar.harvard.edu/sberker) 2015 paper [_Coherentism via Graphs_](https://onlinelibrary.wiley.com/doi/abs/10.1111/phis.12052). Berker eschews the conditional probability relations and instead develops an account which argues that complex graph structures such as [hypergraphs](https://en.wikipedia.org/wiki/Hypergraph) are needed to represent the justificatory structure of beliefs.

I am currently working on applying ideas from infinite graph theory - particularly infinite cycles - to explore graph-theoretic representations of belief and implications for the [regress problem](https://en.wikipedia.org/wiki/Regress_argument). Here's a [recent talk](https://bcmullins.github.io/infinite_cycles/#/) I gave at the [Society for Exact Philosophy](http://meta.phil.ufl.edu/host/sep/index.html) conference.

## Rethinking Academic Publishing
______

This entry is a bit more loosely organized than the rest and is built around a two-part series of papers: [_Scientific Utopia I: Opening Scientific Communication_](https://arxiv.org/abs/1205.1055) and [_Scientific Utopia II: Restructuring Incentives and Practices to Promote Truth Over Publishability_](https://journals.sagepub.com/doi/full/10.1177/1745691612459058). Part I presents a decentralized vision for communicating scientific results and offers steps to reach this state such as allowing open access to all published papers (with a model similar to [arXiv](https://arxiv.org/)) as well as making peer reviews and commentary on research articles widely available. Regarding the latter, the authors stress that these contributions often go unacknowledged and unrewarded. In [_A World Without Referees_](https://www.stat.cmu.edu/~larry/Peer-Review.pdf), [Larry Wasserman](https://www.stat.cmu.edu/~larry/) counters a common objection to this vision:
>"if there does end up being a flood of papers then smart, enterprising people will respond by creating websites and blogs that tell you what’s out there, review papers, etc. That’s a much more open, democratic approach."

Part II surveys approaches taken to make published statistical results more reliable and offers additional measures such as registering study protocols before collecting data, lowering the barriers to publishing, and making sharing data the norm (when it is feasible). This is especially prescient given the [reproducibility crisis](https://www.americanscientist.org/article/the-statistical-crisis-in-science) and methodological critiques such as Gelman and Loken's [_Garden of Forking Paths_](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.694.7217&rep=rep1&type=pdf). While there [has been progress](https://science.sciencemag.org/content/359/6371/9), it's not yet clear what the future of publishing statistical analyses will and ought to look like.

## Privacy Attacks on Machine Learning Models
______

Privacy attacks refer to cases in which an adversary attempts to learn information about a machine learning model given access to the model. Adversaries may have varying degrees of access to a model. For instance, one may recover the coefficients of a linear model from a publish paper or software documentation and know the full model or one may be able to call a API to score data if [a model is deployed as a SaaS product](https://tanzu.vmware.com/content/blog/scoring-as-a-service-to-operationalize-algorithms-for-real-time).

But what information about models could adversaries try to learn? Model inversion attacks attempt to recreate parts of the training data or to learn sensitive attributes for a given record. [_Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing_](https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson_matthew) from 2014 introduces an approach to learn sensitive information about a person such as whether or not they have such-and-such genetic marker from pharmacogenetic models that predict something observable - in this case, [one's optimal Warfarin dosage](https://en.wikipedia.org/wiki/Warfarin#Dosing) - from genetic markers and demographic information. On the security side, the authors discuss the prospect of using [differential privacy](https://en.wikipedia.org/wiki/Differential_privacy) to defend against such attacks.

<img style="margin-left: auto; margin-right: auto; display: block;" width="50%" height="50%"  src="/images/blog/interesting_articles_2020/stealing_ml_models.png">

Model Extraction attacks attempt to reconstruct the model from partial information. [_Stealing Machine Learning Models via Prediction APIs_](https://arxiv.org/abs/1609.02943) from 2016 introduces methods to reconstruct linear models and decision trees - in some cases a completely accurate reconstruction - in the case of classifiers where confidence scores are provided to the adversary in addition to the label on a query. Property Inference attacks seek to learn aggregate properties of the training data that are not explicitly encoded in the data itself. [_Hacking Smart Machines with Smarter Ones_](https://arxiv.org/abs/1306.4447) from 2015 develops an attack in the context of [speech recognition](https://en.wikipedia.org/wiki/Speech_recognition) - the task of transcribing audio to text - to predict whether or not a given model was trained using recordings with an Indian-American accent, a property that may not and likely is not explicitly noted.

Current research in this area looks at ways to formalize these attacks to better understand both the related security properties of various sorts of machine learning models and how to generally defend against these attacks.

## Blockchains and Cryptocurrencies
______

I couldn't end this list without touching on the bandwagon spectacular that is/was Bitcoin, blockchains, and the cryptocurrency ecosystem. For a brief period, news about trading cryptocurrencies and such-and-such company's new blockchain initiative was smothering. I'm sure everyone had that colleague that was skimping on their lunches and deferring their student loans to fuel their portfolio with [Ethereum Tokens](https://blog.coinbase.com/a-beginners-guide-to-ethereum-tokens-fbd5611fe30b) and [Bitcoin futures](https://www.cnbc.com/quotes/?symbol=@BTC.1).

<img style="float: right; display: inline-block; margin: 10px 0px 10px 25px" width="25%" width="30%" height="30%"  src="/images/blog/researchPrograms2010s/blockchain.jpeg">

Rather than technical innovations and what-not, I'm much more interested in the cultural aspects of this phenomenon. David Gerard's [_Attack of the 50 Foot Blockchain_](https://davidgerard.co.uk/blockchain/book/) (also found in my [Top Books in 2018]({{ site.baseurl }}{% link _posts/2018-12-16-Top-Books-2018.md %}#attack-of-the-50-foot-blockchain)) and [blog of the same title](https://davidgerard.co.uk/blockchain/) have been invaluable resources for learning about and documenting cryptocurrency culture with its cypherpunk origins and continual chicanery and shenanigans.

I also want to point you to [Kai Stinchcombe's](https://medium.com/@kaistinchcombe) hot takes (or rather cold water) on blockchain as a practical technology [that companies could build into their products](https://medium.com/@kaistinchcombe/ten-years-in-nobody-has-come-up-with-a-use-case-for-blockchain-ee98c180100) or that could be [utilized at scale in society](https://medium.com/@kaistinchcombe/decentralized-and-trustless-crypto-paradise-is-actually-a-medieval-hellhole-c1ca122efdec).

One positive outcome of the blockchain boom - that I gained from and hope others did as well - is exposure to new ideas and challenges. In my case, these include troubleshooting hardware issues such as [having to use a screwdriver as the power button for a mining rig](https://www.gamersnexus.net/guides/2011-jumping-a-motherboard-without-power-switch-button), fiddling with [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) and [load balancers](https://en.wikipedia.org/wiki/Load_balancing_(computing)) (which was fashionable given the coinciding [progress in deep learning](#image-recognition-and-object-detection)), and absorbing a bit of [cryptography](https://en.wikipedia.org/wiki/Public-key_cryptography) along the way.
